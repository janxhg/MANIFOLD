"""
Competitive Learning Dynamics Comparison
=========================================

Demonstrates HOW and HOW FAST GFN learns compared to other architectures.

This is the "rivalry showdown" - head-to-head training comparison showing:
- Convergence speed (epochs to target accuracy)
- Sample efficiency (data needed to reach milestones)
- Learning stability (loss variance)
- Generalization dynamics (overfitting vs GFN's physics constraints)
"""

import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from pathlib import Path
import sys
import time
from tqdm import tqdm

PROJECT_ROOT = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from src import GFN, GFNLoss, RiemannianAdam
from src.math_dataset import MathDataset
try:
    from tests.benchmarks.baselines import MicroGPT
except ImportError:
    from baselines import MicroGPT


class LearningDynamicsComparison:
    """Head-to-head training comparison framework."""
    
    def __init__(self, device='cuda'):
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        self.results_dir = PROJECT_ROOT / "tests" / "professional" / "results"
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
        # Training history storage
        self.history = {
            'GFN': {'train_loss': [], 'train_acc': [], 'test_acc': [], 'epoch_time': []},
            'GPT': {'train_loss': [], 'train_acc': [], 'test_acc': [], 'epoch_time': []}
        }
    
    def create_models(self, vocab_size=20, dim=384, depth=8):
        """Create matched models with similar param counts (~1-2M)."""
        
        # Adjusted for fair comparison:
        # GFN needs higher dim because low-rank structure is parameter-efficient
        gfn = GFN(vocab_size=vocab_size, dim=dim, depth=depth, rank=32).to(self.device)
        
        # GPT with fewer heads to match param count
        gpt = MicroGPT(vocab_size=vocab_size, dim=dim//2, depth=depth, heads=4).to(self.device)
        
        # Print param counts
        gfn_params = sum(p.numel() for p in gfn.parameters()) / 1e6
        gpt_params = sum(p.numel() for p in gpt.parameters()) / 1e6
        
        print(f"\nüìä Model Sizes:")
        print(f"  GFN: {gfn_params:.2f}M params")
        print(f"  GPT: {gpt_params:.2f}M params")
        print(f"  Ratio: {gfn_params/gpt_params:.2f}x")
        
        return gfn, gpt
    
    def evaluate_accuracy(self, model, dataset, num_samples=100, model_name='GFN'):
        """Compute accuracy on dataset."""
        model.eval()
        correct = 0
        total = 0
        
        with torch.no_grad():
            for _ in range(num_samples):
                # Generate problem
                problem_str = dataset._generate_problem()
                parts = problem_str.split('=')
                prompt_str = parts[0] + '='
                target_str = parts[1]
                
                # Encode
                ids = [dataset.char_to_id[c] for c in prompt_str]
                input_seq = torch.tensor([ids]).to(self.device)
                
                # Generate prediction
                if model_name == 'GFN':
                    logits, state = model(input_seq)
                    curr_token = torch.argmax(logits[:, -1, :], dim=-1).unsqueeze(0)
                    generated = list(ids) + [curr_token.item()]
                    
                    # Continue generation
                    for _ in range(len(target_str) + 2):
                        logits, state = model(curr_token, state=state)
                        next_token = torch.argmax(logits[:, -1, :], dim=-1)
                        tok_id = next_token.item()
                        if tok_id == dataset.char_to_id.get('<EOS>', -1):
                            break
                        generated.append(tok_id)
                        curr_token = next_token.unsqueeze(0)
                else:  # GPT
                    generated = list(ids)
                    for _ in range(len(target_str) + 2):
                        inp = torch.tensor([generated]).to(self.device)
                        logits = model(inp)
                        next_token = torch.argmax(logits[:, -1, :], dim=-1)
                        tok_id = next_token.item()
                        if tok_id == dataset.char_to_id.get('<EOS>', -1):
                            break
                        generated.append(tok_id)
                
                # Check correctness
                pred_res = dataset.decode(generated).split('=')[-1].strip()
                if pred_res == target_str.strip():
                    correct += 1
                total += 1
        
        return (correct / total) * 100 if total > 0 else 0.0
    
    def train_epoch(self, model, optimizer, criterion, train_loader, model_name='GFN'):
        """Train one epoch."""
        model.train()
        total_loss = 0
        num_batches = 0
        
        for batch in train_loader:
            inputs, targets = batch
            inputs = inputs.to(self.device)
            targets = targets.to(self.device)
            
            optimizer.zero_grad()
            
            if model_name == 'GFN':
                logits, _ = model(inputs)
                loss, _ = criterion(logits, targets)
            else:  # GPT
                logits = model(inputs)
                loss = nn.CrossEntropyLoss()(logits.view(-1, logits.size(-1)), targets.view(-1))
            
            loss.backward()
            
            # Gradient clipping
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            
            optimizer.step()
            
            total_loss += loss.item()
            num_batches += 1
        
        return total_loss / num_batches if num_batches > 0 else 0.0
    
    def run_training_comparison(self, epochs=50, batch_size=32, dataset_size=1000):
        """
        üèÜ MAIN SHOWDOWN: Train both models side-by-side.
        
        Returns detailed training curves showing who learns faster and better.
        """
        print("\n" + "=" * 70)
        print("  ü•ä TRAINING SHOWDOWN: GFN vs GPT")
        print("=" * 70)
        
        # Create models
        gfn, gpt = self.create_models()
        
        # Create dataset
        train_dataset = MathDataset(size=dataset_size, max_digits=2)
        test_dataset = MathDataset(size=200, max_digits=2)
        
        # Create simple dataloader (batch sampling)
        def get_batches(dataset, batch_size):
            batches = []
            for _ in range(dataset_size // batch_size):
                batch_inputs = []
                batch_targets = []
                
                for _ in range(batch_size):
                    problem = dataset._generate_problem()
                    ids = [dataset.char_to_id[c] for c in problem]
                    
                    # Input: everything except last char
                    # Target: everything except first char (shifted by 1)
                    batch_inputs.append(ids[:-1])
                    batch_targets.append(ids[1:])
                
                # Pad to same length
                max_len = max(len(seq) for seq in batch_inputs)
                padded_inputs = [seq + [0] * (max_len - len(seq)) for seq in batch_inputs]
                padded_targets = [seq + [-100] * (max_len - len(seq)) for seq in batch_targets]
                
                batches.append((
                    torch.tensor(padded_inputs),
                    torch.tensor(padded_targets)
                ))
            
            return batches
        
        # Optimizers with higher learning rate for faster convergence
        gfn_optimizer = RiemannianAdam(gfn.parameters(), lr=3e-3)
        gpt_optimizer = torch.optim.AdamW(gpt.parameters(), lr=3e-3, weight_decay=0.01)
        
        # Loss
        gfn_criterion = GFNLoss(lambda_h=0.001)  # Lower physics weight for faster learning
        
        # Training loop
        print(f"\nüîÑ Training for {epochs} epochs...")
        print(f"   Dataset: {dataset_size} samples, Batch: {batch_size}")
        
        # Track milestones
        milestones = {
            'GFN': {'50%': None, '70%': None, '90%': None},
            'GPT': {'50%': None, '70%': None, '90%': None}
        }
        
        for epoch in range(epochs):
            # Get fresh batches
            train_batches = get_batches(train_dataset, batch_size)
            
            # Train GFN (multiple passes per epoch for stability)
            start_time = time.time()
            gfn_loss = 0
            for _ in range(2):  # 2 passes per epoch
                gfn_loss += self.train_epoch(gfn, gfn_optimizer, gfn_criterion, train_batches, 'GFN')
            gfn_loss /= 2
            gfn_epoch_time = time.time() - start_time
            
            # Train GPT (single pass)
            start_time = time.time()
            gpt_loss = self.train_epoch(gpt, gpt_optimizer, nn.CrossEntropyLoss(), train_batches, 'GPT')
            gpt_epoch_time = time.time() - start_time
            
            # Evaluate every 2 epochs (more frequent feedback)
            if epoch % 2 == 0 or epoch == epochs - 1:
                gfn_acc = self.evaluate_accuracy(gfn, test_dataset, num_samples=100, model_name='GFN')
                gpt_acc = self.evaluate_accuracy(gpt, test_dataset, num_samples=100, model_name='GPT')
                
                # Track history
                self.history['GFN']['train_loss'].append(gfn_loss)
                self.history['GFN']['test_acc'].append(gfn_acc)
                self.history['GFN']['epoch_time'].append(gfn_epoch_time)
                
                self.history['GPT']['train_loss'].append(gpt_loss)
                self.history['GPT']['test_acc'].append(gpt_acc)
                self.history['GPT']['epoch_time'].append(gpt_epoch_time)
                
                # Check milestones
                for threshold, label in [(50, '50%'), (70, '70%'), (90, '90%')]:
                    if gfn_acc >= threshold and milestones['GFN'][label] is None:
                        milestones['GFN'][label] = epoch
                    if gpt_acc >= threshold and milestones['GPT'][label] is None:
                        milestones['GPT'][label] = epoch
                
                print(f"  Epoch {epoch:3d} | GFN: Loss={gfn_loss:.4f} Acc={gfn_acc:5.1f}% ({gfn_epoch_time:.2f}s) | "
                      f"GPT: Loss={gpt_loss:.4f} Acc={gpt_acc:5.1f}% ({gpt_epoch_time:.2f}s)")
        
        # Visualize results
        self._plot_training_curves()
        self._plot_convergence_comparison(milestones)
        self._plot_efficiency_metrics()
        
        print("\n‚úì Training comparison complete!")
        return self.history, milestones
    
    def _plot_training_curves(self):
        """Plot training loss and accuracy curves."""
        
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
        
        epochs_eval = np.arange(0, len(self.history['GFN']['train_loss'])) * 5
        
        # Loss curve
        ax1.plot(epochs_eval, self.history['GFN']['train_loss'], 
                linewidth=2.5, marker='o', markersize=6, label='GFN', color='#2A9D8F')
        ax1.plot(epochs_eval, self.history['GPT']['train_loss'], 
                linewidth=2.5, marker='s', markersize=6, label='Transformer', color='#E76F51')
        ax1.set_xlabel('Epoch', fontsize=13)
        ax1.set_ylabel('Training Loss', fontsize=13)
        ax1.set_title('üî• Learning Speed: Loss Convergence', fontsize=15, fontweight='bold')
        ax1.legend(fontsize=11)
        ax1.grid(alpha=0.3)
        
        # Accuracy curve
        ax2.plot(epochs_eval, self.history['GFN']['test_acc'], 
                linewidth=2.5, marker='o', markersize=6, label='GFN', color='#2A9D8F')
        ax2.plot(epochs_eval, self.history['GPT']['test_acc'], 
                linewidth=2.5, marker='s', markersize=6, label='Transformer', color='#E76F51')
        ax2.axhline(y=90, color='green', linestyle='--', alpha=0.5, label='90% Target')
        ax2.set_xlabel('Epoch', fontsize=13)
        ax2.set_ylabel('Test Accuracy (%)', fontsize=13)
        ax2.set_title('üéØ Generalization: Test Accuracy', fontsize=15, fontweight='bold')
        ax2.legend(fontsize=11)
        ax2.grid(alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(self.results_dir / "learning_curves_comparison.png", dpi=300, bbox_inches='tight')
        plt.close()
    
    def _plot_convergence_comparison(self, milestones):
        """Bar chart of epochs needed to reach milestones."""
        
        fig, ax = plt.subplots(figsize=(10, 6))
        
        thresholds = ['50%', '70%', '90%']
        gfn_epochs = [milestones['GFN'][t] if milestones['GFN'][t] is not None else 100 
                     for t in thresholds]
        gpt_epochs = [milestones['GPT'][t] if milestones['GPT'][t] is not None else 100 
                     for t in thresholds]
        
        x = np.arange(len(thresholds))
        width = 0.35
        
        bars1 = ax.bar(x - width/2, gfn_epochs, width, label='GFN', color='#2A9D8F', alpha=0.8)
        bars2 = ax.bar(x + width/2, gpt_epochs, width, label='Transformer', color='#E76F51', alpha=0.8)
        
        # Add value labels
        for bars in [bars1, bars2]:
            for bar in bars:
                height = bar.get_height()
                if height < 100:
                    ax.text(bar.get_x() + bar.get_width()/2., height,
                           f'{int(height)}', ha='center', va='bottom', fontsize=10, fontweight='bold')
                else:
                    ax.text(bar.get_x() + bar.get_width()/2., height - 5,
                           'Not reached', ha='center', va='top', fontsize=9, color='white')
        
        ax.set_xlabel('Accuracy Milestone', fontsize=13)
        ax.set_ylabel('Epochs Required', fontsize=13)
        ax.set_title('‚ö° Convergence Speed Showdown', fontsize=15, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(thresholds)
        ax.legend(fontsize=11)
        ax.grid(alpha=0.3, axis='y')
        
        plt.tight_layout()
        plt.savefig(self.results_dir / "convergence_speed_comparison.png", dpi=300, bbox_inches='tight')
        plt.close()
    
    def _plot_efficiency_metrics(self):
        """Plot training efficiency (time per epoch, etc)."""
        
        fig, ax = plt.subplots(figsize=(10, 6))
        
        gfn_avg_time = np.mean(self.history['GFN']['epoch_time'])
        gpt_avg_time = np.mean(self.history['GPT']['epoch_time'])
        
        gfn_final_acc = self.history['GFN']['test_acc'][-1]
        gpt_final_acc = self.history['GPT']['test_acc'][-1]
        
        # Efficiency = Final Accuracy / Avg Time per Epoch
        gfn_efficiency = gfn_final_acc / gfn_avg_time
        gpt_efficiency = gpt_final_acc / gpt_avg_time
        
        models = ['GFN', 'Transformer']
        efficiencies = [gfn_efficiency, gpt_efficiency]
        colors = ['#2A9D8F', '#E76F51']
        
        bars = ax.bar(models, efficiencies, color=colors, alpha=0.8, edgecolor='black', linewidth=2)
        
        # Add value labels
        for bar, eff in zip(bars, efficiencies):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{eff:.2f}', ha='center', va='bottom', fontsize=12, fontweight='bold')
        
        ax.set_ylabel('Efficiency (Accuracy % / Sec per Epoch)', fontsize=13)
        ax.set_title('üí™ Training Efficiency Comparison', fontsize=15, fontweight='bold')
        ax.grid(alpha=0.3, axis='y')
        
        plt.tight_layout()
        plt.savefig(self.results_dir / "training_efficiency.png", dpi=300, bbox_inches='tight')
        plt.close()


def run_learning_showdown():
    """Main entry point for learning dynamics comparison."""
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"\nüéÆ Device: {device}")
    
    comparator = LearningDynamicsComparison(device=device)
    
    # Run training comparison with adjusted params
    history, milestones = comparator.run_training_comparison(
        epochs=30,  # Fewer epochs but evaluate more often
        batch_size=32,  # Larger batch
        dataset_size=800  # More training data
    )
    
    # Print summary
    print("\n" + "=" * 70)
    print("  üìä SHOWDOWN RESULTS")
    print("=" * 70)
    
    print("\nüèÜ Convergence Speed (Epochs to Milestone):")
    for threshold in ['50%', '70%', '90%']:
        gfn_ep = milestones['GFN'][threshold]
        gpt_ep = milestones['GPT'][threshold]
        
        gfn_str = f"{gfn_ep}" if gfn_ep is not None else "Not reached"
        gpt_str = f"{gpt_ep}" if gpt_ep is not None else "Not reached"
        
        winner = "GFN" if (gfn_ep or 999) < (gpt_ep or 999) else "GPT"
        print(f"  {threshold} Accuracy: GFN={gfn_str:>12s} | GPT={gpt_str:>12s} | Winner: {winner} üèÖ")
    
    print("\nüìà Final Performance:")
    gfn_final = history['GFN']['test_acc'][-1]
    gpt_final = history['GPT']['test_acc'][-1]
    print(f"  GFN: {gfn_final:.1f}%")
    print(f"  GPT: {gpt_final:.1f}%")
    
    print("\n‚úì All plots saved to tests/professional/results/")
    print("  - learning_curves_comparison.png")
    print("  - convergence_speed_comparison.png")
    print("  - training_efficiency.png")
    print("=" * 70)


if __name__ == "__main__":
    run_learning_showdown()
