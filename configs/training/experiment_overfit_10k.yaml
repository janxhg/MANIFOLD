training:
  dataset: 'math'
  dataset_path: 'data/math_10k.txt'
  dataset_size: 10000
  max_digits: 4
  
  # Optimization
  batch_size: 256  # Safe size for deep model
  accumulation_steps: 1
  effective_batch: 256
  
  epochs: 50
  steps_per_epoch: 40  # 10,000 / 256 approx 39.
  
  learning_rate: 1.0e-3
  weight_decay: 1.0e-4
  max_grad_norm: 1.0
  use_amp: true
  
  # Logging
  log_interval: 5
  demo_interval: 5

checkpoint:
  path: 'checkpoints/experiment_10k'
  save_interval: 10
