model:
  dim: 256
  depth: 6
  heads: 4
  vocab_size: 10000  # TinyStories has small vocab, will be updated after loading
  max_len: 512
  use_scan: true
  
physics:
  dt_scale: 0.1
  alpha: 0.99
  solver: "heun"
  active_inference:
    enabled: true
    adaptive_dt: true
    plasticity: true
    
training:
  batch_size: 16  # Larger batch since vocab is smaller
  lr: 3.0e-4  # Slightly higher LR for faster convergence
  epochs: 10
  grad_clip: 1.0
  log_every: 50
  save_dir: "checkpoints/tinystories"
  seed: 42
