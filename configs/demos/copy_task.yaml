model:
  dim: 256  # Smaller model for simple task
  depth: 6
  heads: 8
  vocab_size: 12  # 10 digits + <eos> + <sep>
  max_len: 256
  use_scan: true
  
physics:
  dt_scale: 0.1
  alpha: 0.95
  solver: ""
  active_inference:
    enabled: true
    adaptive_dt: true
    plasticity: true
    
training:
  batch_size: 64
  lr: 5.0e-4
  epochs: 50
  grad_clip: 1.0
  log_every: 20
  save_dir: "checkpoints/copy_task"
  seed: 42
  
task:
  min_length: 5
  max_length: 50  # Test up to 50 tokens
  num_train: 50000
  num_val: 5000
